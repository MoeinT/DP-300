## Azure Load Balancer
Imagine a scenario where there are a large number of requests to a web application hosted in a VM. In order to be able to handle this, we can host the application on multiple machines as part of a Virtual Machine Scale set. In such a scenario, we would need a mechanism to make sure the incoming requests don't fall on the same machine, and get evenly distributed across all machines. For this we can use the Azure Load Balancer service. So, in this case incoming requests from users/internet will go through the Azure Load Balancer first, and get distributed across the VMs. For this reason, if the load balancer is being accessed from the internet, we might need to assign a public IP address to it, and there's no need for the VMs to have one.

**Public and private (internal) load balancers -** Public Load Balancers are used to distribute traffic from the internet to the resources in the backend pool; and they're associated with a public ip address. In private (internal) Load Balancers private ip addresses are needed at the frontend, and are used to route traffic inside a Virtual Network to the backend resources. 

**How to deploy and associate a Load Balancer to a Virtual Machine -**
In order to be able to connect to a Virtual Machine via the public IP of the Load Balancer, we would have to create the following infrastructure:
- [An Azure Load Balancing service](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb) along with a Public IP address attached to it. This is because of the fact that the Load Balancer will route incoming traffic from the internet to the virtual machines in the backend pool.
- We would need to create a [Load Balancer Backend pool](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_backend_address_pool), within which we specify the network interfaces of the Virtual Machines. This way, Load Balancer would know where the incoming requests should be routed to.
- A Load Balancer health probe to assess whether the VMs within the backend pool are up & running and if not, avoid routing the requests to them. Here's the Terraform [documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_probe).
- Load balancing rules to specify frontend and backend ports and other configurations. Here's how we define a LB rule in [Terraform](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_probe).

**NOTE -** If we have a Basic tier for the load balancer, we need to make sure the VMs in the backend pool are part of the same availability set. If not, we would have to go with a Standard tier. Standatd Tier load balancers are able to route traffic to VMs deployed in different availability sets.

**Load Balancer Health Probe -** The role of the Load Balancer is to forward the incoming requests to the VMs running an application. Before doing so, it needs to make sure the VMs are up & running. In case of failure on any of the Virtual Machines, it will avoid forwarding the incoming requests to that VM. Here's the [documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_probe) on how to deploy a Load Balancer health probe.

**Load Balancing Rules -** Through the Load Balancing Rules, we can define how the incoming requests should be routed to the VMs hosting the application. There might be multiple backend pools attached to the Load Balancer, so using the Load Balancing Rules, we can define to which backend pool should the incoming requests be forwarded to. Here's the Terraform [documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_rule.html).

**Load Balancer Standard Sku -** One difference is that for the Basic tier, all virtual machines should be part of the same availability set, or scaleset in order to be able to get attached to the LB backend pool; with the standard Sku, however, this is not a limitation. Another difference is that with the Standard Sku, all outbound traffic is blocked by default for the VMs in the backend pool. We need to explicitly add an outbound rule to the Load Balancer.

**NAT (Network Address Translation) rules -** Imagine a scenario where a load balancer at the frontend distributes the traffic to the backend virtual machines, and is assigned a public IP address. So, we can send requests from the internet to the load balancer on a specific port, and access the VMs at the backend on a specific port (both backend and frontend ports can be defined within the LB rules). In this scenario, the backend VMs do not have and do not need a public IP address assigned to them, and therefore there's no way to log into them directly. In such cases, we can configure something known as NAT Rules. We can actually use a single public IP address that's assigned onto the load balancer to actually log into VMs at the backend. Using the NAT rule, we can define frontend and backend ports and a desktop remote connection to connect directly to the VMs using Load Balancers IP address.